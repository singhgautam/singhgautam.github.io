<!DOCTYPE html>
<html lang="en">
<head>
  <title>Gautam Singh</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
  <style>
    /* Remove the navbar's default margin-bottom and rounded borders */
    .navbar {
      margin-bottom: 0;
      border-radius: 0;
    }

    /*div.content { width: 1000px;     margin-left: auto;*/
    /*margin-right: auto; }*/

    body {
        margin: 1em auto;
        max-width: 60%;
        /*font-family: 'Lato', sans-serif;*/
        font-family: Gill Sans,Gill Sans MT,Calibri;
        font-size: 20px;
      }

    /* Add a gray background color and some padding to the footer */
    footer {
      background-color: #f2f2f2;
      padding: 25px;
    }
  </style>
</head>
<body>


<div class="content">
<h1>Gautam Singh</h1>
<p>lastname.firstname@rutgers.edu &middot; <a href="https://drive.google.com/file/d/1GX5Xn1rGImO3S0BvjEO8fWofax61LhrS/view?usp=sharing">CV</a> &middot; <a href="https://twitter.com/gautamsi11">Twitter</a> &middot; <a href="https://www.linkedin.com/in/gautam-singh-61302463/">LinkedIn</a> &middot; <a href="https://github.com/singhgautam">Github</a> &middot; <a href="https://scholar.google.co.in/citations?hl=en&amp;user=lXpFxDwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Scholar</a></p>
<p>&nbsp;</p>
<p>I am a Ph.D. candidate in the Department of <a href="https://www.cs.rutgers.edu/">Computer Science</a> at <a href="http://www.rutgers.edu/">Rutgers University</a>, advised by <a href="http://sungjinahn.com/">Prof. Sungjin Ahn</a>.</p>
<p>My interests lie at the intersection of <em>unsupervised scene representation learning</em>, <em>object-centric learning</em>, and <em>compositionality</em>. My research aims to build a fully-unsupervised object-centric perception system, using modern-day deep learning, that can act as a backbone to support human-like cognitive abilities (planning, reasoning, systematic generalization) in artificial agents. I consider the term <em>object</em> in a broad sense to include any type of regularities that can be combined together to build a model of the world e.g. objects, parts, properties, temporal abstractions, relations, etc.</p>
<p>I spent the summer of 2021 as an Applied Scientist Intern at Amazon. Before starting a Ph.D. in 2018, I worked at <a href="https://www.research.ibm.com/labs/india/">IBM Research India</a>. In 2015, I received a Bachelor of Technology degree from <a href="https://www.iitg.ac.in/">Indian Institute of Technology (IIT) Guwahati</a>. I also spent a summer at <a href="kaist.ac.kr">Korea Advanced Institute of Science and Technology (KAIST)</a> as a research intern in 2014.</p>
<p>&nbsp;</p>
<hr />
<h3>News</h3>
<ul>
<li><em>Nov 2022:&nbsp;</em>Preprint of our new work, <a href="https://arxiv.org/abs/2211.01177">Neural Block-Slot Representations</a>, for unsupervised disentanglement of within-slot factors of variation, is out on arXiv! See our project page <a href="https://sites.google.com/view/block-slot-attention">here</a>.</li>
<li><em>Sep 2022: </em>Our recent work, <a href="https://arxiv.org/abs/2205.14065">STEVE</a>, has been accepted at NeurIPS 2022.</li>
<li><em>May 2022:&nbsp;</em>Preprint of our new work, <a href="https://arxiv.org/abs/2205.14065">STEVE</a>, for unsupervised decomposition of complex and naturalistic videos is out on Arxiv! See our project page <a href="https://sites.google.com/view/slot-transformer-for-videos">here</a>.&nbsp;</li>
<li><em>Jan 2022:</em> Our recent work, <a href="https://arxiv.org/abs/2110.11405">SLATE</a>, has been accepted at ICLR 2022 and was also presented at the NeurIPS 2021 Workshop on "Controllable Generative Modeling in Language and Vision".</li>
<li><em>Oct 2021:</em> Preprint of our new work, <a href="https://arxiv.org/abs/2110.11405">SLATE</a>, for building a text-free DALL-E via object-centric learning is out on <a href="https://arxiv.org/pdf/2110.11405.pdf">Arxiv</a>! Our code is released <a href="https://github.com/singhgautam/slate">here</a> and the project page <a href="https://sites.google.com/view/slate-autoencoder">here</a>.</li>
</ul>
<hr />
<h3>Publications</h3>
<p>&nbsp;</p>
<ul>
<li>Neural Block-Slot Representations<br />
<ul>
<li><span style="text-decoration: underline;">Gautam Singh</span>, Yeongbin Kim, Sungjin Ahn</li>
<li><em>Preprint</em>&nbsp;[<a href="https://arxiv.org/pdf/2211.01177.pdf">pdf</a>] [<a href="https://sites.google.com/view/block-slot-attention">project</a>]</li>
</ul>
</li>
</ul>
<ul>
<li>Simple Unsupervised Object-Centric Learning for Complex and Naturalistic Videos<br />
<ul>
<li><span style="text-decoration: underline;">Gautam Singh</span>, Yi-Fu Wu, Sungjin Ahn</li>
<li><em>NeurIPS 2022</em>&nbsp;[<a href="https://arxiv.org/pdf/2205.14065.pdf">pdf</a>] [<a href="https://drive.google.com/file/d/1bE9i0lNVQBj3Dbp6cLHqXOpuj23u4Tv8/view?usp=sharing">poster</a>] [<a href="https://sites.google.com/view/slot-transformer-for-videos">project</a>] [<a href="https://github.com/singhgautam/steve">code</a>]</li>
</ul>
</li>
</ul>
<ul>
<li>Illiterate DALL-E Learns to Compose
<ul>
<li><span style="text-decoration: underline;">Gautam Singh</span>, Fei Deng, Sungjin Ahn</li>
<li><em>ICLR 2022</em> [<a href="https://arxiv.org/pdf/2110.11405.pdf">pdf</a>] [<a href="https://sites.google.com/view/slate-autoencoder">project</a>] [<a href="https://github.com/singhgautam/slate">code</a>]</li>
</ul>
</li>
</ul>
<ul>
<li>Structured World Belief for Reinforcement Learning in POMDP
<ul>
<li><span style="text-decoration: underline;">Gautam Singh</span>, Skand Peri, Junghyun Kim, Hyunseok Kim, Sungjin Ahn</li>
<li><em>ICML 2021</em> [<a href="https://arxiv.org/pdf/2107.08577">pdf</a>] [<a href="https://sites.google.com/view/structuredworldbelief">project</a>]</li>
</ul>
</li>
</ul>
<ul>
<li>Robustifying Sequential Neural Processes
<ul>
<li>Jaesik Yoon, <span style="text-decoration: underline;">Gautam Singh</span>, Sungjin Ahn</li>
<li><em>ICML 2020</em> [<a href="https://arxiv.org/pdf/2006.15987">pdf</a>]</li>
</ul>
</li>
</ul>
<ul>
<li>SPACE: Unsupervised Object-Oriented Scene Representation via Spatial Attention and Decomposition
<ul>
<li>{Zhixuan Lin, Yi-Fu Wu, Skand Vishwanath Peri}, Weihao Sun, <span style="text-decoration: underline;">Gautam Singh</span>, Fei Deng, Jindong Jiang, Sungjin Ahn</li>
<li><em>ICLR 2020</em> [<a href="https://arxiv.org/pdf/2001.02407">pdf</a>] [<a href="https://sites.google.com/view/space-project-page">project</a>]</li>
</ul>
</li>
</ul>
<ul>
<li>Sequential Neural Processes
<ul>
<li>{<span style="text-decoration: underline;">Gautam Singh</span>, Jaesik Yoon}, Sungjin Ahn</li>
<li><em>NeurIPS 2019</em> (Spotlight) [<a href="https://arxiv.org/pdf/1906.10264">pdf</a>] [<a href="https://sites.google.com/view/sequential-neural-processes">project</a>] [<a href="https://github.com/singhgautam/snp">code</a>]</li>
</ul>
</li>
</ul>
<hr />
<h3>Media</h3>
<ul>
<li><em>Oct 2021:</em> <a href="https://www.marktechpost.com/2021/10/26/rutgers-universitys-ai-researchers-propose-a-slot-based-autoencoder-architecture-called-slot-attention-transformer-slate/">Rutgers University&rsquo;s AI Researchers Propose A Slot-Based Autoencoder Architecture, Called SLot Attention TransformEr (SLATE)</a></li>
</ul>
<hr />
<h3>Service</h3>
<ul>
<li>Conference Reviewer: ICLR23, NeurIPS22, ICML22</li>
<li>Workshop Reviewer: OSC@ICLR22</li>
</ul>
</div>


</body>
</html>
