<!DOCTYPE html>
<html lang="en">
<head>
  <title>Gautam Singh</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
  <style>
    /* Remove the navbar's default margin-bottom and rounded borders */
    .navbar {
      margin-bottom: 0;
      border-radius: 0;
    }

    /*div.content { width: 1000px;     margin-left: auto;*/
    /*margin-right: auto; }*/

    body {
        margin: 1em auto;
        max-width: 60%;
        /*font-family: 'Lato', sans-serif;*/
        font-family: Gill Sans,Gill Sans MT,Calibri;
        font-size: 20px;
      }

    /* Add a gray background color and some padding to the footer */
    footer {
      background-color: #f2f2f2;
      padding: 25px;
    }
  </style>
</head>
<body>


<div class="content">
<h1>Gautam Singh</h1>
<p>lastname.firstname@rutgers.edu &middot; <a href="https://drive.google.com/file/d/1GX5Xn1rGImO3S0BvjEO8fWofax61LhrS/view?usp=sharing">CV</a> &middot; <a href="https://twitter.com/gautamsi11">Twitter</a> &middot; <a href="https://www.linkedin.com/in/gautam-singh-61302463/">LinkedIn</a> &middot; <a href="https://github.com/singhgautam">Github</a> &middot; <a href="https://scholar.google.co.in/citations?hl=en&amp;user=lXpFxDwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Scholar</a></p>

  <img src="picture.png" alt="Gautam Singh" height="192px" style="border-radius: 30px; margin-bottom: 10px; margin-top: 10px;">

  <p>I am a final year Ph.D. candidate in the Department of <a href="https://www.cs.rutgers.edu/">Computer Science</a> at <a href="http://www.rutgers.edu/">Rutgers University</a>, advised by <a href="https://mlml.kaist.ac.kr/sungjinahn">Prof. Sungjin Ahn</a>.<span style="color: brown; font-size: 0.9em;"> ✨ I am on the job market for industry research positions and post-doc positions. ✨</span> </p>
  <p>I am interested in <strong>perception</strong> and <strong>world modeling</strong> from unstructured sensory inputs (e.g., vision) for supporting generalization to out-of-distribution and long-tail scenarios in agent learning tasks. I pursue <strong>unsupervised learning</strong> or <strong>self-supervised learning</strong> approaches and try to develop scalable architectures to harness the full potential of all available unlabeled data and <strong>large-scale training</strong> in the long run. Towards perception, I have focused on two important aspects of the structure of the physical world for learning scene representations: <strong>object-centric modularity</strong> and awareness of the <strong>3D space and time</strong>.</p>
<p>I am currently a part-time Research Intern at <a href="https://nvr-avg.github.io/">NVIDIA Research - Autonomous Vehicle Research Group</a>. I spent the summer of 2021 as an Applied Scientist Intern at <a href="https://www.amazon.science/tag/supply-chain-optimization-technologies">Amazon</a>. Before starting a Ph.D. in 2018, I was a researcher at <a href="https://www.research.ibm.com/labs/india/">IBM India Research Lab (IRL)</a>. In 2015, I received a Bachelor of Technology degree from <a href="https://www.iitg.ac.in/">IIT Guwahati</a>. I also spent a summer at <a href="kaist.ac.kr">KAIST</a> as a research intern in 2014.</p>
<p>&nbsp;</p>
<hr />
<h2>Recent News</h2>
<ul>
  <li><em>Feb 2024: </em> Our new work, <a href="https://singhgautam.github.io/">Parallelized Spatiotemporal Binding</a>, is now on <a href="https://arxiv.org/abs/2402.17077">arXiv</a>!</li>
<li><em>Sep 2023: </em> Joined as a research intern at <a href="https://nvr-avg.github.io/">NVIDIA Research</a> collaborating with <a href="https://scholar.google.com/citations?user=7b5tlJkAAAAJ&amp;hl=en">Gerry Che</a> and <a href="https://yuewang.xyz/">Yue Wang</a>.</li>
<li><em>May 2023: </em> Gave a talk at the <a href="https://robotics.cs.toronto.edu/toronto-air/">Toronto AI in Robotics (AIR)</a> seminar, focusing on representation learning for systematic generalization. YouTube link <a href="https://youtu.be/fa96vWAN108">here</a>!</li>
<li><em>Feb 2023: </em> We have released the code and datasets for our ICLR'23 paper Neural Systematic Binder <a href="https://github.com/singhgautam/sysbinder">here</a>!</li>
</ul>
<hr />
<h2 style="margin-bottom: 0;">Selected Publications</h2> <small style="margin-top: 0;">Equal contributions are denoted using {}.</small>
<div style="height: 1em;"></div>
  <h3>2024</h3>
<ul>
 <li><strong>Parallelized Spatiotemporal Binding</strong><br />
<ul>
<li><span style="text-decoration: underline;">Gautam Singh</span>, Yue Wang, Jiawei Yang, Boris Ivanovic, {Sungjin Ahn, Marco Pavone}, Tong Che</li>
<li><em>ICML 2024</em>&nbsp;[<a href="https://arxiv.org/pdf/2402.17077.pdf">pdf</a>] [<a href="https://parallel-st-binder.github.io/">project</a>]</li>
</ul>
</li>
</ul>
<h3>2023</h3>
<ul>
 <li><strong>Imagine the Unseen World: A Systematic Visual Imagination Benchmark</strong><br />
<ul>
<li>{Yeongbin Kim, <span style="text-decoration: underline;">Gautam Singh</span>}, Junyeong Park, Caglar Gulcehre, Sungjin Ahn</li>
<li><em>NeurIPS 2023</em>&nbsp;</li>
</ul>
</li>
</ul>
<ul>
<li><strong>Object-Centric Slot Diffusion</strong><br />
<ul>
<li>Jindong Jiang, Fei Deng, <span style="text-decoration: underline;">Gautam Singh</span>, Sungjin Ahn</li>
<li><em>NeurIPS 2023 (Spotlight)</em>&nbsp;[<a href="https://arxiv.org/pdf/2303.10834.pdf">pdf</a>]</li>
</ul>
</li>
</ul>
<ul>
<li><strong>Neural Systematic Binder</strong><br />
<ul>
<li><span style="text-decoration: underline;">Gautam Singh</span>, Yeongbin Kim, Sungjin Ahn</li>
<li><em>ICLR 2023</em>&nbsp;[<a href="https://arxiv.org/pdf/2211.01177.pdf">pdf</a>] [<a href="https://sites.google.com/view/neural-systematic-binder">project</a>] [<a href="https://github.com/singhgautam/sysbinder">code</a>] [<a href="https://drive.google.com/drive/folders/1FKEjZnKfu9KnSGfnr8oGVUBSPqnptzJc?usp=sharing">data</a>]</li>
</ul>
</li>
</ul>
<h3>2022</h3>
<ul>
<li><strong>Simple Unsupervised Object-Centric Learning for Complex and Naturalistic Videos</strong><br />
<ul>
<li><span style="text-decoration: underline;">Gautam Singh</span>, Yi-Fu Wu, Sungjin Ahn</li>
<li><em>NeurIPS 2022</em>&nbsp;[<a href="https://arxiv.org/pdf/2205.14065.pdf">pdf</a>] [<a href="https://drive.google.com/file/d/1bE9i0lNVQBj3Dbp6cLHqXOpuj23u4Tv8/view?usp=sharing">poster</a>] [<a href="https://sites.google.com/view/slot-transformer-for-videos">project</a>] [<a href="https://github.com/singhgautam/steve">code</a>] [<a href="https://drive.google.com/drive/folders/1lWjVU_DurT5Cu-amR4RoqQvd7cvheQDF?usp=share_link">data</a>]</li>
</ul>
</li>
</ul>
<ul>
<li><strong>Illiterate DALL-E Learns to Compose</strong>
<ul>
<li><span style="text-decoration: underline;">Gautam Singh</span>, Fei Deng, Sungjin Ahn</li>
<li><em>ICLR 2022</em> [<a href="https://arxiv.org/pdf/2110.11405.pdf">pdf</a>] [<a href="https://sites.google.com/view/slate-autoencoder">project</a>] [<a href="https://github.com/singhgautam/slate">code</a>]</li>
</ul>
</li>
</ul>
<h3>2021</h3>
<ul>
<li><strong>Structured World Belief for Reinforcement Learning in POMDP</strong>
<ul>
<li><span style="text-decoration: underline;">Gautam Singh</span>, Skand Peri, Junghyun Kim, Hyunseok Kim, Sungjin Ahn</li>
<li><em>ICML 2021</em> [<a href="https://arxiv.org/pdf/2107.08577">pdf</a>] [<a href="https://sites.google.com/view/structuredworldbelief">project</a>]</li>
</ul>
</li>
</ul>
<h3>2020</h3>
<ul>
<li><strong>Robustifying Sequential Neural Processes</strong>
<ul>
<li>Jaesik Yoon, <span style="text-decoration: underline;">Gautam Singh</span>, Sungjin Ahn</li>
<li><em>ICML 2020</em> [<a href="https://arxiv.org/pdf/2006.15987">pdf</a>]</li>
</ul>
</li>
</ul>
<ul>
<li><strong>SPACE: Unsupervised Object-Oriented Scene Representation via Spatial Attention and Decomposition</strong>
<ul>
<li>{Zhixuan Lin, Yi-Fu Wu, Skand Vishwanath Peri}, Weihao Sun, <span style="text-decoration: underline;">Gautam Singh</span>, Fei Deng, Jindong Jiang, Sungjin Ahn</li>
<li><em>ICLR 2020</em> [<a href="https://arxiv.org/pdf/2001.02407">pdf</a>] [<a href="https://sites.google.com/view/space-project-page">project</a>]</li>
</ul>
</li>
</ul>
<h3>2019</h3>
<ul>
<li><strong>Sequential Neural Processes</strong>
<ul>
<li>{<span style="text-decoration: underline;">Gautam Singh</span>, Jaesik Yoon}, Sungjin Ahn</li>
<li><em>NeurIPS 2019</em> (Spotlight) [<a href="https://arxiv.org/pdf/1906.10264">pdf</a>] [<a href="https://sites.google.com/view/sequential-neural-processes">project</a>] [<a href="https://github.com/singhgautam/snp">code</a>]</li>
</ul>
</li>
</ul>
<hr />
<h2>Media</h2>
<ul>
<li><em>Oct 2021:</em> <a href="https://www.marktechpost.com/2021/10/26/rutgers-universitys-ai-researchers-propose-a-slot-based-autoencoder-architecture-called-slot-attention-transformer-slate/">Rutgers University&rsquo;s AI Researchers Propose A Slot-Based Autoencoder Architecture, Called SLot Attention TransformEr (SLATE)</a></li>
</ul>
<hr />
<h2>Service</h2>
<ul>
<li>Conference Reviewer: ICML24, NeurIPS23, ICLR23, NeurIPS22, ICML22</li>
<li>Workshop Reviewer: OSC@ICLR22</li>
</ul>
</div>


</body>
</html>
