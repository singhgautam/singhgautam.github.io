<!DOCTYPE html>
<html lang="en">
<head>
  <title>Gautam Singh</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
  <style>
    /* Remove the navbar's default margin-bottom and rounded borders */
    .navbar {
      margin-bottom: 0;
      border-radius: 0;
    }

    /*div.content { width: 1000px;     margin-left: auto;*/
    /*margin-right: auto; }*/

    body {
        margin: 1em auto;
        max-width: 60%;
        /*font-family: 'Lato', sans-serif;*/
        font-family: Gill Sans,Gill Sans MT,Calibri;
        font-size: 16px;
      }

    /* Add a gray background color and some padding to the footer */
    footer {
      background-color: #f2f2f2;
      padding: 25px;
    }
  </style>
</head>
<body>


<div class="content">
<h1>Gautam Singh</h1>
<p><a href="https://drive.google.com/file/d/1c2szMzPd-Iu4Tzj83gpgON9P-r-5VPDF/view?usp=sharing">CV</a> &middot; <a href="https://twitter.com/gautamsi11">X</a> &middot; <a href="https://www.linkedin.com/in/gautam-singh-61302463/">LinkedIn</a> &middot; <a href="https://github.com/singhgautam">Github</a> &middot; <a href="https://scholar.google.co.in/citations?hl=en&amp;user=lXpFxDwAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Scholar</a></p>

  <img src="picture.png" alt="Gautam Singh" height="128px" style="border-radius: 20px; margin-bottom: 10px; margin-top: 10px;">

  <p>ML Postdoctoral Research Staff @
<a href="https://computing.llnl.gov/casc/ml">Lawrence Livermore National Laboratory (LLNL)</a>
</p>
  <p>I am interested in making generative models & large language models capable of human-like out-of-distribution generalization and learn sample-efficiently. I am also interested in applications of machine learning for code generation/understanding and addressing difficult scientific challenges.</p>
<p>
In the past, I held internships at
<a href="https://nvr-avg.github.io/">NVIDIA Research</a>
and
<a href="https://www.amazon.science/tag/supply-chain-optimization-technologies">Amazon</a>,
and I spent three years working at
<a href="https://www.research.ibm.com/labs/india/">IBM Research</a>.
I obtained a B.Tech. at
<a href="https://www.iitg.ac.in/">IIT Guwahati</a>
and a Ph.D. in
<a href="https://www.cs.rutgers.edu/">Computer Science</a>
at
<a href="http://www.rutgers.edu/">Rutgers University</a>, advised by
<a href="https://mlml.kaist.ac.kr/sungjinahn">Prof. Sungjin Ahn</a>.
</p>
<p>&nbsp;</p>
    <div class="company-logos" aria-label="Affiliations Held">
  <img src="logos/llnl.png" alt="Lawrence Livermore National Laboratory (LLNL)" />
  <img src="logos/nvidia.png" alt="NVIDIA Research" />
  <img src="logos/amazon-science.svg" alt="Amazon Science logo" />
  <img src="logos/rutgers.png" alt="Rutgers University logo" />
  <img src="logos/ibm_research.svg" alt="IBM Research logo" />
  <img src="logos/kaist.png" alt="KAIST logo" />
  <img src="logos/iitm.png" alt="IIT Madras logo" />
  <img src="logos/iitg.png" alt="IIT Guwahati logo" />
</div>

<style>
  .company-logos{
    display:flex;
    flex-direction:row;
    align-items:center;
    gap:14px;
    flex-wrap:nowrap;      /* keeps it a single row */
    overflow-x:auto;       /* allows horizontal scroll if needed */
    padding:4px 0;
  }
  .company-logos img{
    height:32px;           /* adjust as you like */
    width:auto;
    max-width:120px;       /* prevents one logo from dominating */
    object-fit:contain;
    display:block;
  }
</style>
<hr />
<h2>Recent News</h2>
<ul>
  <li><em>May 2024: </em> Our work, <a href="https://parallel-st-binder.github.io/">Parallelized Spatiotemporal Binding</a>, has now been accepted at ICML 2024!</li>
  <li><em>Feb 2024: </em> Our new work, <a href="https://parallel-st-binder.github.io/">Parallelized Spatiotemporal Binding</a>, is now on <a href="https://arxiv.org/abs/2402.17077">arXiv</a>!</li>
<li><em>Sep 2023: </em> Joined as a research intern at <a href="https://nvr-avg.github.io/">NVIDIA Research</a> collaborating with <a href="https://scholar.google.com/citations?user=7b5tlJkAAAAJ&amp;hl=en">Gerry Che</a> and <a href="https://yuewang.xyz/">Yue Wang</a>.</li>
<li><em>May 2023: </em> Gave a talk at the University of Toronto <a href="https://robotics.cs.toronto.edu/toronto-air/">AI in Robotics (AIR)</a> seminar, focusing on representation learning for systematic generalization. YouTube link <a href="https://youtu.be/fa96vWAN108">here</a>!</li>
<li><em>Feb 2023: </em> We have released the code and datasets for our ICLR'23 paper Neural Systematic Binder <a href="https://github.com/singhgautam/sysbinder">here</a>!</li>
</ul>
<hr />
<h2 style="margin-bottom: 0;">Selected Publications</h2> <small style="margin-top: 0;">Equal contributions are denoted using {}.</small>
<div style="height: 1em;"></div>
<h3>2025</h3>
 <ul>
 <li><strong>Can Program Search Help LLMs Write Better Parallel Code?</strong><br />
<ul>
<li><span style="text-decoration: underline;">Gautam Singh</span>, Arjun Guha, Bhavya Kailkhura, Harshitha Menon</li>
<li><em>NeurIPS 2025 Workshop (DL4C)</em>&nbsp</li>
</ul>
</li>
</ul>
<ul>
 <li><strong>Dreamweaver: Learning Compositional World Representations from Pixels</strong><br />
<ul>
<li>Junyeob Baek, Yi-Fu Wu, <span style="text-decoration: underline;">Gautam Singh</span>, Sungjin Ahn</li>
<li><em>ICLR 2025</em>&nbsp;[<a href="https://arxiv.org/pdf/2501.14174">pdf</a>]</li>
</ul>
</li>
</ul>
<h3>2024</h3>
<ul>
 <li><strong>Slot State Space Models</strong><br />
<ul>
<li>Jindong Jiang, Fei Deng, <span style="text-decoration: underline;">Gautam Singh</span>, Minseung Lee, Sungjin Ahn</li>
<li><em>NeurIPS 2024</em>&nbsp;[<a href="https://arxiv.org/pdf/2406.12272">pdf</a>] [<a href="https://slotssms.github.io/">project</a>]</li>
</ul>
</li>
</ul>
<ul>
 <li><strong>Parallelized Spatiotemporal Binding</strong><br />
<ul>
<li><span style="text-decoration: underline;">Gautam Singh</span>, Yue Wang, Jiawei Yang, Boris Ivanovic, {Sungjin Ahn, Marco Pavone}, Tong Che</li>
<li><em>ICML 2024</em>&nbsp;[<a href="https://arxiv.org/pdf/2402.17077.pdf">pdf</a>] [<a href="https://parallel-st-binder.github.io/">project</a>]</li>
</ul>
</li>
</ul>
<h3>2023</h3>
<ul>
 <li><strong>Imagine the Unseen World: A Systematic Visual Imagination Benchmark</strong><br />
<ul>
<li>{Yeongbin Kim, <span style="text-decoration: underline;">Gautam Singh</span>}, Junyeong Park, Caglar Gulcehre, Sungjin Ahn</li>
<li><em>NeurIPS 2023</em>&nbsp;</li>
</ul>
</li>
</ul>
<ul>
<li><strong>Object-Centric Slot Diffusion</strong><br />
<ul>
<li>Jindong Jiang, Fei Deng, <span style="text-decoration: underline;">Gautam Singh</span>, Sungjin Ahn</li>
<li><em>NeurIPS 2023 (Spotlight)</em>&nbsp;[<a href="https://arxiv.org/pdf/2303.10834.pdf">pdf</a>]</li>
</ul>
</li>
</ul>
<ul>
<li><strong>Neural Systematic Binder</strong><br />
<ul>
<li><span style="text-decoration: underline;">Gautam Singh</span>, Yeongbin Kim, Sungjin Ahn</li>
<li><em>ICLR 2023</em>&nbsp;[<a href="https://arxiv.org/pdf/2211.01177.pdf">pdf</a>] [<a href="https://sites.google.com/view/neural-systematic-binder">project</a>] [<a href="https://github.com/singhgautam/sysbinder">code</a>] [<a href="https://drive.google.com/drive/folders/1FKEjZnKfu9KnSGfnr8oGVUBSPqnptzJc?usp=sharing">data</a>]</li>
</ul>
</li>
</ul>
<h3>2022</h3>
<ul>
<li><strong>Simple Unsupervised Object-Centric Learning for Complex and Naturalistic Videos</strong><br />
<ul>
<li><span style="text-decoration: underline;">Gautam Singh</span>, Yi-Fu Wu, Sungjin Ahn</li>
<li><em>NeurIPS 2022</em>&nbsp;[<a href="https://arxiv.org/pdf/2205.14065.pdf">pdf</a>] [<a href="https://drive.google.com/file/d/1bE9i0lNVQBj3Dbp6cLHqXOpuj23u4Tv8/view?usp=sharing">poster</a>] [<a href="https://sites.google.com/view/slot-transformer-for-videos">project</a>] [<a href="https://github.com/singhgautam/steve">code</a>] [<a href="https://drive.google.com/drive/folders/1lWjVU_DurT5Cu-amR4RoqQvd7cvheQDF?usp=share_link">data</a>]</li>
</ul>
</li>
</ul>
<ul>
<li><strong>Illiterate DALL-E Learns to Compose</strong>
<ul>
<li><span style="text-decoration: underline;">Gautam Singh</span>, Fei Deng, Sungjin Ahn</li>
<li><em>ICLR 2022</em> [<a href="https://arxiv.org/pdf/2110.11405.pdf">pdf</a>] [<a href="https://sites.google.com/view/slate-autoencoder">project</a>] [<a href="https://github.com/singhgautam/slate">code</a>]</li>
</ul>
</li>
</ul>
<h3>2021</h3>
<ul>
<li><strong>Structured World Belief for Reinforcement Learning in POMDP</strong>
<ul>
<li><span style="text-decoration: underline;">Gautam Singh</span>, Skand Peri, Junghyun Kim, Hyunseok Kim, Sungjin Ahn</li>
<li><em>ICML 2021</em> [<a href="https://arxiv.org/pdf/2107.08577">pdf</a>] [<a href="https://sites.google.com/view/structuredworldbelief">project</a>]</li>
</ul>
</li>
</ul>
<h3>2020</h3>
<ul>
<li><strong>Robustifying Sequential Neural Processes</strong>
<ul>
<li>Jaesik Yoon, <span style="text-decoration: underline;">Gautam Singh</span>, Sungjin Ahn</li>
<li><em>ICML 2020</em> [<a href="https://arxiv.org/pdf/2006.15987">pdf</a>]</li>
</ul>
</li>
</ul>
<ul>
<li><strong>SPACE: Unsupervised Object-Oriented Scene Representation via Spatial Attention and Decomposition</strong>
<ul>
<li>{Zhixuan Lin, Yi-Fu Wu, Skand Vishwanath Peri}, Weihao Sun, <span style="text-decoration: underline;">Gautam Singh</span>, Fei Deng, Jindong Jiang, Sungjin Ahn</li>
<li><em>ICLR 2020</em> [<a href="https://arxiv.org/pdf/2001.02407">pdf</a>] [<a href="https://sites.google.com/view/space-project-page">project</a>]</li>
</ul>
</li>
</ul>
<h3>2019</h3>
<ul>
<li><strong>Sequential Neural Processes</strong>
<ul>
<li>{<span style="text-decoration: underline;">Gautam Singh</span>, Jaesik Yoon}, Sungjin Ahn</li>
<li><em>NeurIPS 2019</em> (Spotlight) [<a href="https://arxiv.org/pdf/1906.10264">pdf</a>] [<a href="https://sites.google.com/view/sequential-neural-processes">project</a>] [<a href="https://github.com/singhgautam/snp">code</a>]</li>
</ul>
</li>
</ul>
<hr />
<h2>Media Coverage</h2>
<ul>
<li><em>Jul 2023:</em> <a href="https://breakthrough.kaist.ac.kr/sub02/view/id/61">AI self-learns to discover the structure of the world like humans</a></li>
</ul>
<ul>
<li><em>Oct 2021:</em> <a href="https://www.marktechpost.com/2021/10/26/rutgers-universitys-ai-researchers-propose-a-slot-based-autoencoder-architecture-called-slot-attention-transformer-slate/">Rutgers University&rsquo;s AI Researchers Propose A Slot-Based Autoencoder Architecture, Called SLot Attention TransformEr (SLATE)</a></li>
</ul>
<hr />
<h2>Service</h2>
<ul>
<li>Conference Reviewer: NeurIPS25, ICML25, ICML24, NeurIPS23, ICLR23, NeurIPS22, ICML22</li>
<li>Workshop Reviewer: OSC@ICLR22</li>
</ul>
</div>


</body>
</html>
